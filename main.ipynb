{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "99c8e298",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch pandas sklearn yfinance boto3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0b144c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json, boto3, datetime, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Module, GRU, Linear, LSTM\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "now = datetime.now() + timedelta(hours=8)\n",
    "dt_string_file = now.strftime(\"%d_%m_%y\")\n",
    "dt_string_yf = now.strftime(\"%Y-%m-%d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6a6f38ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config_QQQ:\n",
    "\n",
    "    etf = \"QQQ\"\n",
    "\n",
    "    dataset_type = \"qqq\"\n",
    "\n",
    "    feature_columns = list(range(1,7))\n",
    "    label_columns = [2,3]\n",
    "    label_in_feature_index = (lambda x,y: [x.index(i) for i in y])(feature_columns, label_columns)\n",
    "\n",
    "    predict_day = 1\n",
    "\n",
    "    model_type = \"gru\"\n",
    "    train_data_rate = 0.95\n",
    "\n",
    "    do_train = True\n",
    "    do_predict = True\n",
    "    time_step = 20\n",
    "    valid_data_rate = 0.15\n",
    "    random_seed = 42\n",
    "    shuffle_train_data = True\n",
    "\n",
    "    input_size = len(feature_columns)\n",
    "    output_size = len(label_columns)\n",
    "    hidden_size = 128       \n",
    "    layers = 2\n",
    "    dropout_rate = 0.2\n",
    "    batch_size = 64\n",
    "    learning_rate = 0.001\n",
    "    epoch = 100\n",
    "    do_continue_train = False\n",
    "    do_train_visualized = False\n",
    "    patience = 5\n",
    "    \n",
    "    model_save_path = \"models/\"\n",
    "    if not os.path.exists(model_save_path):\n",
    "        os.makedirs(model_save_path)\n",
    "\n",
    "    data_save_path = \"dataset/\"\n",
    "    if not os.path.exists(data_save_path):\n",
    "        os.makedirs(data_save_path)\n",
    "\n",
    "class Data_QQQ:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.data, self.data_column_name = self.read_data()\n",
    "\n",
    "        self.data_num = self.data.shape[0]\n",
    "        self.train_num = int(self.data_num * self.config.train_data_rate)\n",
    "\n",
    "        # Normalization\n",
    "        self.mean = np.mean(self.data, axis=0) \n",
    "        self.std = np.std(self.data, axis=0)\n",
    "        self.norm_data = (self.data - self.mean)/self.std \n",
    "\n",
    "    def read_data(self):\n",
    "        df = yf.download(self.config.etf, end=dt_string_yf)\n",
    "        df.to_csv(self.config.data_save_path+self.config.etf+\".csv\")\n",
    "        df = pd.read_csv(self.config.data_save_path+self.config.etf+\".csv\", usecols=self.config.feature_columns)\n",
    "        return df.values, df.columns.tolist()\n",
    "\n",
    "    def get_train_and_valid_data(self):\n",
    "        feature_data = self.norm_data[:self.train_num]\n",
    "        label_data = self.norm_data[self.config.predict_day : self.config.predict_day + self.train_num,\n",
    "                                    self.config.label_in_feature_index]\n",
    "\n",
    "        train_x = [feature_data[start_index + i*self.config.time_step : start_index + (i+1)*self.config.time_step]\n",
    "                        for start_index in range(self.config.time_step)\n",
    "                        for i in range((self.train_num - start_index) // self.config.time_step)]\n",
    "        train_y = [label_data[start_index + i*self.config.time_step : start_index + (i+1)*self.config.time_step]\n",
    "                    for start_index in range(self.config.time_step)\n",
    "                    for i in range((self.train_num - start_index) // self.config.time_step)]\n",
    "\n",
    "        train_x, train_y = np.array(train_x), np.array(train_y)\n",
    "\n",
    "        train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, \n",
    "        test_size=self.config.valid_data_rate, random_state=self.config.random_seed, \n",
    "        shuffle=self.config.shuffle_train_data)\n",
    "        \n",
    "        return train_x, valid_x, train_y, valid_y\n",
    "\n",
    "    def get_test_data(self):\n",
    "        feature_data = self.norm_data[self.train_num:]\n",
    "        sample_interval = min(feature_data.shape[0], self.config.time_step)\n",
    "        self.start_num_in_test = feature_data.shape[0] % sample_interval\n",
    "        time_step_size = feature_data.shape[0] // sample_interval\n",
    "\n",
    "        test_x = [feature_data[self.start_num_in_test+i*sample_interval : self.start_num_in_test+(i+1)*sample_interval]\n",
    "                   for i in range(time_step_size)]\n",
    "\n",
    "        return np.array(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "35428ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config_top10:\n",
    "\n",
    "    etf = \"QQQ\"\n",
    "    tickers = [\"AAPL\", \"MSFT\", \"AMZN\", \"TSLA\", \"GOOG\", \"FB\", \"GOOGL\", \"NVDA\", \"PYPL\", \"ADBE\"]\n",
    "\n",
    "    dataset_type = \"top10\"    \n",
    "\n",
    "    feature_columns = list(range(0,22))\n",
    "    label_columns = [20,21]\n",
    "    label_in_feature_index = (lambda x,y: [x.index(i) for i in y])(feature_columns, label_columns)\n",
    "\n",
    "    predict_day = 1\n",
    "\n",
    "    model_type = \"gru\"\n",
    "    train_data_rate = 0.95\n",
    "\n",
    "    do_train = True\n",
    "    do_predict = True\n",
    "    time_step = 20\n",
    "    valid_data_rate = 0.15\n",
    "    random_seed = 42\n",
    "    shuffle_train_data = True\n",
    "\n",
    "    input_size = len(feature_columns)\n",
    "    output_size = len(label_columns)\n",
    "    hidden_size = 128       \n",
    "    layers = 2\n",
    "    dropout_rate = 0.2\n",
    "    batch_size = 64\n",
    "    learning_rate = 0.001\n",
    "    epoch = 100\n",
    "    do_continue_train = False\n",
    "    do_train_visualized = False\n",
    "    patience = 5\n",
    "\n",
    "    model_save_path = \"models/\"\n",
    "    if not os.path.exists(model_save_path):\n",
    "        os.makedirs(model_save_path)\n",
    "\n",
    "    data_save_path = \"dataset/\"\n",
    "    if not os.path.exists(data_save_path):\n",
    "        os.makedirs(data_save_path)\n",
    "\n",
    "class Data_top10:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.data, self.data_column_name = self.read_data()\n",
    "\n",
    "        self.data_num = self.data.shape[0]\n",
    "        self.train_num = int(self.data_num * self.config.train_data_rate)\n",
    "\n",
    "        # Normalization\n",
    "        self.mean = np.mean(self.data, axis=0) \n",
    "        self.std = np.std(self.data, axis=0)\n",
    "        self.norm_data = (self.data - self.mean)/self.std \n",
    "\n",
    "    def read_data(self):\n",
    "        tickers = self.config.tickers\n",
    "        tickers.append(self.config.etf)\n",
    "        ticker_list = yf.Tickers(tickers)\n",
    "        df = {}\n",
    "        for ticker in tickers:\n",
    "            if ticker != \"QQQ\":\n",
    "                df[ticker+\"_High\"] = ticker_list.tickers[ticker].history(start=\"2016-01-01\", end=dt_string_yf)['High']\n",
    "                df[ticker+\"_Low\"] = ticker_list.tickers[ticker].history(start=\"2016-01-01\", end=dt_string_yf)['Low']\n",
    "            else:\n",
    "                df[\"High\"] = ticker_list.tickers[ticker].history(start=\"2016-01-01\", end=dt_string_yf)['High']\n",
    "                df[\"Low\"] = ticker_list.tickers[ticker].history(start=\"2016-01-01\", end=dt_string_yf)['Low']\n",
    "        df = pd.DataFrame(df)\n",
    "        df.to_csv(self.config.data_save_path+\"top10\"+\".csv\")\n",
    "        return df.values, df.columns.tolist()\n",
    "\n",
    "    def get_train_and_valid_data(self):\n",
    "        feature_data = self.norm_data[:self.train_num]\n",
    "        label_data = self.norm_data[self.config.predict_day : self.config.predict_day + self.train_num,\n",
    "                                    self.config.label_in_feature_index]\n",
    "\n",
    "        train_x = [feature_data[start_index + i*self.config.time_step : start_index + (i+1)*self.config.time_step]\n",
    "                        for start_index in range(self.config.time_step)\n",
    "                        for i in range((self.train_num - start_index) // self.config.time_step)]\n",
    "        train_y = [label_data[start_index + i*self.config.time_step : start_index + (i+1)*self.config.time_step]\n",
    "                    for start_index in range(self.config.time_step)\n",
    "                    for i in range((self.train_num - start_index) // self.config.time_step)]\n",
    "\n",
    "        train_x, train_y = np.array(train_x), np.array(train_y)\n",
    "\n",
    "        train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, \n",
    "        test_size=self.config.valid_data_rate, random_state=self.config.random_seed, \n",
    "        shuffle=self.config.shuffle_train_data)\n",
    "        \n",
    "        return train_x, valid_x, train_y, valid_y\n",
    "\n",
    "    def get_test_data(self):\n",
    "        feature_data = self.norm_data[self.train_num:]\n",
    "        sample_interval = min(feature_data.shape[0], self.config.time_step)\n",
    "        self.start_num_in_test = feature_data.shape[0] % sample_interval\n",
    "        time_step_size = feature_data.shape[0] // sample_interval\n",
    "\n",
    "        test_x = [feature_data[self.start_num_in_test+i*sample_interval : self.start_num_in_test+(i+1)*sample_interval]\n",
    "                   for i in range(time_step_size)]\n",
    "\n",
    "        return np.array(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "7e7c58ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(Module):\n",
    "    def __init__(self, input_size, hidden_size, layers, output_size, dropout_rate):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                         num_layers=layers, batch_first=True, dropout=dropout_rate)\n",
    "        self.linear = Linear(in_features=hidden_size, out_features=output_size)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        lstm_out, hidden = self.lstm(x, hidden)\n",
    "        linear_out = self.linear(lstm_out)\n",
    "        return linear_out, hidden\n",
    "\n",
    "def lstm_train(config, train_and_valid_data):\n",
    "    \n",
    "    train_X, train_Y, valid_X, valid_Y = train_and_valid_data\n",
    "    \n",
    "    train_X, train_Y = torch.from_numpy(train_X).float(), torch.from_numpy(train_Y).float() # To Tensor\n",
    "    train_loader = DataLoader(TensorDataset(train_X, train_Y), batch_size=config.batch_size, drop_last=True)\n",
    "    \n",
    "    valid_X, valid_Y = torch.from_numpy(valid_X).float(), torch.from_numpy(valid_Y).float() #To Tensor\n",
    "    valid_loader = DataLoader(TensorDataset(valid_X, valid_Y), batch_size=config.batch_size, drop_last=True)\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = LSTM(config.input_size, config.hidden_size, config.layers, config.output_size, config.dropout_rate).to(device)\n",
    "    \n",
    "    optimizer =  torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "    criterion = torch.nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    valid_loss_min = float(\"inf\")\n",
    "    bad_epoch = 0\n",
    "    global_step = 0\n",
    "    \n",
    "    for epoch in range(config.epoch):\n",
    "        print(\"Epoch {}/{}\".format(epoch, config.epoch))\n",
    "        model.train()\n",
    "        train_loss_array = []\n",
    "        hidden_train = None\n",
    "        for i, _data in enumerate(train_loader):\n",
    "            _train_X, _train_Y = _data[0].to(device),_data[1].to(device)\n",
    "            optimizer.zero_grad()               \n",
    "            pred_Y, hidden_train = model(_train_X, hidden_train)    \n",
    "            hidden_train = None\n",
    "            #if not config.do_continue_train:\n",
    "            #    hidden_train = None\n",
    "            #else:\n",
    "            #    h_0, c_0 = hidden_train\n",
    "            #    h_0.detach_(), c_0.detach_()    \n",
    "            #    hidden_train = (h_0, c_0)\n",
    "            loss = criterion(pred_Y, _train_Y)  \n",
    "            loss.backward()                     \n",
    "            optimizer.step()                    \n",
    "            train_loss_array.append(loss.item())\n",
    "            global_step += 1\n",
    "            if config.do_train_visualized and global_step % 100 == 0: \n",
    "                vis.line(X=np.array([global_step]), Y=np.array([loss.item()]), win='Train_Loss',\n",
    "                         update='append' if global_step > 0 else None, name='Train', opts=dict(showlegend=True))\n",
    "\n",
    "        model.eval()                    \n",
    "        valid_loss_array = []\n",
    "        hidden_valid = None\n",
    "        for _valid_X, _valid_Y in valid_loader:\n",
    "            _valid_X, _valid_Y = _valid_X.to(device), _valid_Y.to(device)\n",
    "            pred_Y, hidden_valid = model(_valid_X, hidden_valid)\n",
    "            #if not config.do_continue_train: hidden_valid = None\n",
    "            loss = criterion(pred_Y, _valid_Y)  \n",
    "            valid_loss_array.append(loss.item())\n",
    "\n",
    "        train_loss_cur = np.mean(train_loss_array)\n",
    "        valid_loss_cur = np.mean(valid_loss_array)\n",
    "        print(\"The train loss is {:.6f}. \".format(train_loss_cur) +\n",
    "              \"The valid loss is {:.6f}.\".format(valid_loss_cur))\n",
    "        if config.do_train_visualized:      \n",
    "            vis.line(X=np.array([epoch]), Y=np.array([train_loss_cur]), win='Epoch_Loss',\n",
    "                     update='append' if epoch > 0 else None, name='Train', opts=dict(showlegend=True))\n",
    "            vis.line(X=np.array([epoch]), Y=np.array([valid_loss_cur]), win='Epoch_Loss',\n",
    "                     update='append' if epoch > 0 else None, name='Eval', opts=dict(showlegend=True))\n",
    "\n",
    "        if valid_loss_cur < valid_loss_min:\n",
    "            valid_loss_min = valid_loss_cur\n",
    "            bad_epoch = 0\n",
    "            torch.save(model.state_dict(), config.model_save_path + config.model_type + \"_\" + config.dataset_type + \"_model_\"+ dt_string_file+ \".pth\")\n",
    "        else:\n",
    "            bad_epoch += 1\n",
    "            if bad_epoch >= config.patience:    # Stop training if bad epoch\n",
    "                print(\" The training stops early in epoch {}\".format(epoch))\n",
    "                break\n",
    "\n",
    "def lstm_predict(config, test_X):\n",
    "\n",
    "    test_X = torch.from_numpy(test_X).float()\n",
    "    test_set = TensorDataset(test_X)\n",
    "    test_loader = DataLoader(test_set, batch_size=1)\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = LSTM(config.input_size, config.hidden_size, config.layers, config.output_size, config.dropout_rate).to(device)\n",
    "    model.load_state_dict(torch.load(config.model_save_path + config.model_type + \"_\" + config.dataset_type + \"_model_\" + dt_string_file + \".pth\"))\n",
    "\n",
    "    result = torch.Tensor().to(device)\n",
    "\n",
    "    model.eval()\n",
    "    hidden_predict = None\n",
    "    for _data in test_loader:\n",
    "        data_X = _data[0].to(device)\n",
    "        pred_X, hidden_predict = model(data_X, hidden_predict)\n",
    "        # if not config.do_continue_train: hidden_predict = None \n",
    "        cur_pred = torch.squeeze(pred_X, dim=0)\n",
    "        result = torch.cat((result, cur_pred), dim=0)\n",
    "\n",
    "    return result.detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5abe9677",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(Module):\n",
    "    def __init__(self, input_size, hidden_size, layers, output_size, dropout_rate):\n",
    "        super(GRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layers = layers\n",
    "        \n",
    "        self.gru = nn.GRU(input_size, hidden_size, layers, batch_first=True, dropout=dropout_rate)\n",
    "        self.fc = Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        #h0 = torch.zeros(self.layers, x.size(0), self.hidden_size).requires_grad_()\n",
    "        gru_out, hidden = self.gru(x, hidden)\n",
    "        out = self.fc(gru_out) \n",
    "        return out, hidden\n",
    "\n",
    "def gru_train(config, train_and_valid_data):\n",
    "    train_X, train_Y, valid_X, valid_Y = train_and_valid_data\n",
    "    \n",
    "    train_X, train_Y = torch.from_numpy(train_X).float(), torch.from_numpy(train_Y).float() # To Tensor\n",
    "    train_loader = DataLoader(TensorDataset(train_X, train_Y), batch_size=config.batch_size, drop_last=True)\n",
    "    \n",
    "    valid_X, valid_Y = torch.from_numpy(valid_X).float(), torch.from_numpy(valid_Y).float() #To Tensor\n",
    "    valid_loader = DataLoader(TensorDataset(valid_X, valid_Y), batch_size=config.batch_size, drop_last=True)\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = GRU(config.input_size, config.hidden_size, config.layers, config.output_size, config.dropout_rate).to(device)\n",
    "    \n",
    "    optimizer =  torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    \n",
    "    valid_loss_min = float(\"inf\")\n",
    "    bad_epoch = 0\n",
    "    global_step = 0\n",
    "    \n",
    "    for epoch in range(config.epoch):\n",
    "        print(\"Epoch {}/{}\".format(epoch, config.epoch))\n",
    "        model.train()\n",
    "        train_loss_array = []\n",
    "        hidden_train = None\n",
    "        for i, _data in enumerate(train_loader):\n",
    "            _train_X, _train_Y = _data[0].to(device),_data[1].to(device)\n",
    "            optimizer.zero_grad()               \n",
    "            pred_Y, hidden_train = model(_train_X, hidden_train)    \n",
    "            hidden_train = None\n",
    "            #if not config.do_continue_train:\n",
    "            #    hidden_train = None\n",
    "            #else:\n",
    "            #    h_0, c_0 = hidden_train\n",
    "            #    h_0.detach_(), c_0.detach_()    \n",
    "            #    hidden_train = (h_0, c_0)\n",
    "            loss = criterion(pred_Y, _train_Y)  \n",
    "            loss.backward()                     \n",
    "            optimizer.step()                    \n",
    "            train_loss_array.append(loss.item())\n",
    "            global_step += 1\n",
    "            if config.do_train_visualized and global_step % 100 == 0: \n",
    "                vis.line(X=np.array([global_step]), Y=np.array([loss.item()]), win='Train_Loss',\n",
    "                         update='append' if global_step > 0 else None, name='Train', opts=dict(showlegend=True))\n",
    "\n",
    "        model.eval()\n",
    "        valid_loss_array = []\n",
    "        hidden_valid = None\n",
    "        for _valid_X, _valid_Y in valid_loader:\n",
    "            _valid_X, _valid_Y = _valid_X.to(device), _valid_Y.to(device)\n",
    "            pred_Y, hidden_valid = model(_valid_X, hidden_valid)\n",
    "            #if not config.do_continue_train: hidden_valid = None\n",
    "            loss = criterion(pred_Y, _valid_Y)  \n",
    "            valid_loss_array.append(loss.item())\n",
    "\n",
    "        train_loss_cur = np.mean(train_loss_array)\n",
    "        valid_loss_cur = np.mean(valid_loss_array)\n",
    "        print(\"The train loss is {:.6f}. \".format(train_loss_cur) +\n",
    "              \"The valid loss is {:.6f}.\".format(valid_loss_cur))\n",
    "        if config.do_train_visualized:      \n",
    "            vis.line(X=np.array([epoch]), Y=np.array([train_loss_cur]), win='Epoch_Loss',\n",
    "                     update='append' if epoch > 0 else None, name='Train', opts=dict(showlegend=True))\n",
    "            vis.line(X=np.array([epoch]), Y=np.array([valid_loss_cur]), win='Epoch_Loss',\n",
    "                     update='append' if epoch > 0 else None, name='Eval', opts=dict(showlegend=True))\n",
    "\n",
    "        if valid_loss_cur < valid_loss_min:\n",
    "            valid_loss_min = valid_loss_cur\n",
    "            bad_epoch = 0\n",
    "            torch.save(model.state_dict(), config.model_save_path + config.model_type + \"_\" + config.dataset_type + \"_model_\" + dt_string_file + \".pth\")\n",
    "        else:\n",
    "            bad_epoch += 1\n",
    "            if bad_epoch >= config.patience:    # Stop training if bad epoch\n",
    "                print(\" The training stops early in epoch {}\".format(epoch))\n",
    "                break\n",
    "\n",
    "def gru_predict(config, test_X):\n",
    "\n",
    "    test_X = torch.from_numpy(test_X).float()\n",
    "    test_set = TensorDataset(test_X)\n",
    "    test_loader = DataLoader(test_set, batch_size=1)\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = GRU(config.input_size, config.hidden_size, config.layers, config.output_size, config.dropout_rate).to(device)\n",
    "    model.load_state_dict(torch.load(config.model_save_path + config.model_type + \"_\" + config.dataset_type + \"_model_\" + dt_string_file + \".pth\"))\n",
    "\n",
    "    result = torch.Tensor().to(device)\n",
    "\n",
    "    model.eval()\n",
    "    hidden_predict = None\n",
    "    for _data in test_loader:\n",
    "        data_X = _data[0].to(device)\n",
    "        pred_X, hidden_predict = model(data_X, hidden_predict)\n",
    "        # if not config.do_continue_train: hidden_predict = None \n",
    "        cur_pred = torch.squeeze(pred_X, dim=0)\n",
    "        result = torch.cat((result, cur_pred), dim=0)\n",
    "\n",
    "    return result.detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ff76c1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(config):\n",
    "\n",
    "    config_dict = {}\n",
    "    for key in dir(config):\n",
    "        if not key.startswith(\"_\"):\n",
    "            config_dict[key] = getattr(config, key)\n",
    "            \n",
    "    if config.dataset_type == \"qqq\":\n",
    "        dataset = Data_QQQ(config)\n",
    "    elif config.dataset_type == \"top10\":\n",
    "        dataset = Data_top10(config)\n",
    "        \n",
    "    if config.do_train:\n",
    "        train_X, valid_X, train_Y, valid_Y = dataset.get_train_and_valid_data()\n",
    "        if config.model_type == \"gru\":\n",
    "            gru_train(config, [train_X, train_Y, valid_X, valid_Y])\n",
    "        elif config.model_type == \"lstm\":\n",
    "            lstm_train(config, [train_X, train_Y, valid_X, valid_Y])\n",
    "\n",
    "    if config.do_predict:\n",
    "        test_X = dataset.get_test_data()\n",
    "        if config.model_type == \"gru\":\n",
    "            pred_result = gru_predict(config, test_X)\n",
    "        elif config.model_type == \"lstm\":\n",
    "            pred_result = lstm_predict(config, test_X)\n",
    "    \n",
    "    label_data = dataset.data[dataset.train_num + dataset.start_num_in_test : ,\n",
    "                                            config.label_in_feature_index]\n",
    "    predict_data = pred_result * dataset.std[config.label_in_feature_index] + \\\n",
    "                dataset.mean[config.label_in_feature_index]\n",
    "\n",
    "    label_name = [dataset.data_column_name[i] for i in config.label_in_feature_index]\n",
    "    label_column_num = len(config.label_columns)\n",
    "\n",
    "    loss = np.mean((label_data[config.predict_day:] - predict_data[:-config.predict_day] ) ** 2, axis=0)\n",
    "    loss_norm = loss/(dataset.std[config.label_in_feature_index] ** 2)\n",
    "    print(\"The mean squared error of stock {} is \".format(label_name) + str(loss_norm))\n",
    "\n",
    "    label_X = range(dataset.data_num - dataset.train_num - dataset.start_num_in_test)\n",
    "    predict_X = [ x + config.predict_day for x in label_X]\n",
    "\n",
    "    for i in range(label_column_num):\n",
    "        try:\n",
    "            config_dict[label_name[i]] = int(np.squeeze(predict_data[-config.predict_day:, i]))\n",
    "        except:\n",
    "            a = list(np.squeeze(predict_data[-config.predict_day:, i]))\n",
    "            a.reverse()\n",
    "            config_dict[label_name[i]] = a\n",
    "        print(\"The predicted stock {} for the next {} day(s) is: \".format(label_name[i],\n",
    "        config.predict_day) + str(np.squeeze(predict_data[-config.predict_day:, i])))\n",
    "        \n",
    "    path_log = \"log/\" + config.dataset_type + \"_\" + config.model_type+\"_\" + dt_string_file + \".json\"\n",
    "    path_model = \"models/\" + config.model_type+ \"_\" + config.dataset_type + \"_model_\" + dt_string_file + \".pth\"\n",
    "    path_dataset = \"dataset/\"\n",
    "    with open(path_log, \"w\") as outfile:\n",
    "        json.dump(config_dict, outfile, indent = 1)\n",
    "    \n",
    "    bucket = \"stockpricestorage\"\n",
    "    s3 = boto3.resource('s3')\n",
    "    s3.meta.client.upload_file(path_log, bucket, path_log)\n",
    "    s3.meta.client.upload_file(path_model, bucket, path_model)\n",
    "    for root,dirs,files in os.walk(path_dataset):\n",
    "        for file in files:\n",
    "            s3.meta.client.upload_file(os.path.join(root,file),bucket, path_dataset+file)\n",
    "    print(\"successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "95148257",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/100\n",
      "The train loss is 0.303939. The valid loss is 0.142448.\n",
      "Epoch 1/100\n",
      "The train loss is 0.083956. The valid loss is 0.086421.\n",
      "Epoch 2/100\n",
      "The train loss is 0.038653. The valid loss is 0.040694.\n",
      "Epoch 3/100\n",
      "The train loss is 0.024191. The valid loss is 0.031182.\n",
      "Epoch 4/100\n",
      "The train loss is 0.017865. The valid loss is 0.023587.\n",
      "Epoch 5/100\n",
      "The train loss is 0.013736. The valid loss is 0.019103.\n",
      "Epoch 6/100\n",
      "The train loss is 0.010458. The valid loss is 0.014847.\n",
      "Epoch 7/100\n",
      "The train loss is 0.007964. The valid loss is 0.011869.\n",
      "Epoch 8/100\n",
      "The train loss is 0.006091. The valid loss is 0.009605.\n",
      "Epoch 9/100\n",
      "The train loss is 0.004777. The valid loss is 0.007919.\n",
      "Epoch 10/100\n",
      "The train loss is 0.003948. The valid loss is 0.007166.\n",
      "Epoch 11/100\n",
      "The train loss is 0.003307. The valid loss is 0.006422.\n",
      "Epoch 12/100\n",
      "The train loss is 0.002992. The valid loss is 0.006151.\n",
      "Epoch 13/100\n",
      "The train loss is 0.002738. The valid loss is 0.005878.\n",
      "Epoch 14/100\n",
      "The train loss is 0.002552. The valid loss is 0.005844.\n",
      "Epoch 15/100\n",
      "The train loss is 0.002547. The valid loss is 0.005856.\n",
      "Epoch 16/100\n",
      "The train loss is 0.002386. The valid loss is 0.006062.\n",
      "Epoch 17/100\n",
      "The train loss is 0.002403. The valid loss is 0.006394.\n",
      "Epoch 18/100\n",
      "The train loss is 0.002276. The valid loss is 0.006183.\n",
      "Epoch 19/100\n",
      "The train loss is 0.002260. The valid loss is 0.006223.\n",
      " The training stops early in epoch 19\n",
      "The mean squared error of stock ['High', 'Low'] is [0.01684211 0.02424512]\n",
      "The predicted stock High for the next 1 day(s) is: 358.8700969484969\n",
      "The predicted stock Low for the next 1 day(s) is: 351.9318351889687\n",
      "successful\n",
      "The mean squared error of stock ['High', 'Low'] is [0.03369016 0.04656153]\n",
      "The predicted stock High for the next 5 day(s) is: [369.6523511  367.69117289 360.3768887  360.15540454 358.87009729]\n",
      "The predicted stock Low for the next 5 day(s) is: [362.69185019 360.77319108 353.49628511 353.23121117 351.93182383]\n",
      "successful\n",
      "Epoch 0/100\n",
      "The train loss is 0.171884. The valid loss is 0.053209.\n",
      "Epoch 1/100\n",
      "The train loss is 0.035590. The valid loss is 0.027966.\n",
      "Epoch 2/100\n",
      "The train loss is 0.019495. The valid loss is 0.018654.\n",
      "Epoch 3/100\n",
      "The train loss is 0.012828. The valid loss is 0.014494.\n",
      "Epoch 4/100\n",
      "The train loss is 0.009413. The valid loss is 0.012634.\n",
      "Epoch 5/100\n",
      "The train loss is 0.007132. The valid loss is 0.010437.\n",
      "Epoch 6/100\n",
      "The train loss is 0.005634. The valid loss is 0.008104.\n",
      "Epoch 7/100\n",
      "The train loss is 0.004553. The valid loss is 0.006509.\n",
      "Epoch 8/100\n",
      "The train loss is 0.003827. The valid loss is 0.005360.\n",
      "Epoch 9/100\n",
      "The train loss is 0.003407. The valid loss is 0.004437.\n",
      "Epoch 10/100\n",
      "The train loss is 0.003157. The valid loss is 0.004027.\n",
      "Epoch 11/100\n",
      "The train loss is 0.002925. The valid loss is 0.003743.\n",
      "Epoch 12/100\n",
      "The train loss is 0.002713. The valid loss is 0.003367.\n",
      "Epoch 13/100\n",
      "The train loss is 0.002575. The valid loss is 0.003237.\n",
      "Epoch 14/100\n",
      "The train loss is 0.002491. The valid loss is 0.003254.\n",
      "Epoch 15/100\n",
      "The train loss is 0.002357. The valid loss is 0.003342.\n",
      "Epoch 16/100\n",
      "The train loss is 0.002303. The valid loss is 0.003548.\n",
      "Epoch 17/100\n",
      "The train loss is 0.002215. The valid loss is 0.003818.\n",
      "Epoch 18/100\n",
      "The train loss is 0.002237. The valid loss is 0.003960.\n",
      " The training stops early in epoch 18\n",
      "The mean squared error of stock ['High', 'Low'] is [0.0224433  0.02229748]\n",
      "The predicted stock High for the next 1 day(s) is: 362.2584334502695\n",
      "The predicted stock Low for the next 1 day(s) is: 349.6809251728049\n",
      "successful\n",
      "The mean squared error of stock ['High', 'Low'] is [0.04004938 0.04758048]\n",
      "The predicted stock High for the next 5 day(s) is: [372.5196328  370.91501128 365.49083126 364.12056349 362.25844412]\n",
      "The predicted stock Low for the next 5 day(s) is: [360.70076442 358.99662857 353.01744642 351.59996888 349.68092508]\n",
      "successful\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 0/100\n",
      "The train loss is 0.104948. The valid loss is 0.034973.\n",
      "Epoch 1/100\n",
      "The train loss is 0.012809. The valid loss is 0.013302.\n",
      "Epoch 2/100\n",
      "The train loss is 0.005072. The valid loss is 0.005106.\n",
      "Epoch 3/100\n",
      "The train loss is 0.002429. The valid loss is 0.003107.\n",
      "Epoch 4/100\n",
      "The train loss is 0.001733. The valid loss is 0.002710.\n",
      "Epoch 5/100\n",
      "The train loss is 0.001457. The valid loss is 0.002804.\n",
      "Epoch 6/100\n",
      "The train loss is 0.001305. The valid loss is 0.003177.\n",
      "Epoch 7/100\n",
      "The train loss is 0.001190. The valid loss is 0.003439.\n",
      "Epoch 8/100\n",
      "The train loss is 0.001103. The valid loss is 0.003848.\n",
      "Epoch 9/100\n",
      "The train loss is 0.000977. The valid loss is 0.004391.\n",
      " The training stops early in epoch 9\n",
      "The mean squared error of stock ['High', 'Low'] is [0.01368288 0.02019283]\n",
      "The predicted stock High for the next 1 day(s) is: 344.39314708360763\n",
      "The predicted stock Low for the next 1 day(s) is: 337.2616337191105\n",
      "successful\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "The mean squared error of stock ['High', 'Low'] is [0.02285187 0.03218851]\n",
      "The predicted stock High for the next 5 day(s) is: [353.47237723 350.00332178 345.08994977 343.80167857 344.35175929]\n",
      "The predicted stock Low for the next 5 day(s) is: [345.99772473 342.65266715 337.96471388 336.64356541 337.2221732 ]\n",
      "successful\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 0/100\n",
      "The train loss is 0.047435. The valid loss is 0.011604.\n",
      "Epoch 1/100\n",
      "The train loss is 0.005822. The valid loss is 0.003982.\n",
      "Epoch 2/100\n",
      "The train loss is 0.002553. The valid loss is 0.002494.\n",
      "Epoch 3/100\n",
      "The train loss is 0.001660. The valid loss is 0.002689.\n",
      "Epoch 4/100\n",
      "The train loss is 0.001331. The valid loss is 0.003464.\n",
      "Epoch 5/100\n",
      "The train loss is 0.001118. The valid loss is 0.004760.\n",
      "Epoch 6/100\n",
      "The train loss is 0.001014. The valid loss is 0.006519.\n",
      "Epoch 7/100\n",
      "The train loss is 0.000934. The valid loss is 0.008836.\n",
      " The training stops early in epoch 7\n",
      "The mean squared error of stock ['High', 'Low'] is [0.03691413 0.03707773]\n",
      "The predicted stock High for the next 1 day(s) is: 341.04332984251977\n",
      "The predicted stock Low for the next 1 day(s) is: 335.79752075679863\n",
      "successful\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "The mean squared error of stock ['High', 'Low'] is [0.04531869 0.04838989]\n",
      "The predicted stock High for the next 5 day(s) is: [347.18149285 344.09489956 339.64538706 339.24287959 341.01813639]\n",
      "The predicted stock Low for the next 5 day(s) is: [342.21896093 339.32176822 335.08998731 334.42047655 335.77365673]\n",
      "successful\n"
     ]
    }
   ],
   "source": [
    "config_QQQ = Config_QQQ()\n",
    "config_top10 = Config_top10()\n",
    "\n",
    "config_top10.predict_day = 1\n",
    "config_top10.do_train = True\n",
    "config_top10.model_type = \"lstm\"\n",
    "main(config_top10)\n",
    "\n",
    "config_top10.do_train = False\n",
    "config_top10.predict_day = 5\n",
    "main(config_top10)\n",
    "\n",
    "config_top10.predict_day = 1\n",
    "config_top10.do_train = True\n",
    "config_top10.model_type = \"gru\"\n",
    "main(config_top10)\n",
    "\n",
    "config_top10.do_train = False\n",
    "config_top10.predict_day = 5\n",
    "main(config_top10)\n",
    "\n",
    "config_QQQ.predict_day = 1\n",
    "config_QQQ.do_train = True\n",
    "config_QQQ.model_type = \"lstm\"\n",
    "main(config_QQQ)\n",
    "\n",
    "config_QQQ.do_train = False\n",
    "config_QQQ.predict_day = 5\n",
    "main(config_QQQ)\n",
    "\n",
    "config_QQQ.predict_day = 1\n",
    "config_QQQ.do_train = True\n",
    "config_QQQ.model_type = \"gru\"\n",
    "main(config_QQQ)\n",
    "\n",
    "config_QQQ.do_train = False\n",
    "config_QQQ.predict_day = 5\n",
    "main(config_QQQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293b3c48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565de4fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279325e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e552899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf07dce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fdfa78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcb4755",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce82800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9d8dc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e2a3b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
